{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPARK METRIC EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input EventLog JSON file & Output directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_absolute_path = \"C:/Users/shivam.verma/Desktop/event_logs/application_1587909807967_89833\"\n",
    "output_dir = \"C:/Users/shivam.verma/Desktop/event_logs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create spark session & read json as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Spark Event Log Metrics Collector\").enableHiveSupport().getOrCreate()\n",
    "metrics = spark.read.json(\"file:///\" + file_absolute_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query execution details\n",
    "* query: contains query text. To show query in event log, set sparkContext.setLocalProperty(\"callSite.long\", query) where query is variable containing the query text.\n",
    "* execution_start_time: execution start time of query in millisec.\n",
    "* execution_end_time: execution end time of query in millisec.\n",
    "* execution_time: total time taken in executing the query in millisec.\n",
    "* numStages: number of stages used in executing query\n",
    "* numTasks: number of tasks used in executing query\n",
    "* executorCpuTime: total executor CPU time used in executing query in millisec.\n",
    "* memoryBytesSpilled: total memory spilled while executing query in bytes.\n",
    "* peakExecutionMemory: max execution memory used while executing query in bytes.\n",
    "* recordsRead: number of records read while executing query.\n",
    "* bytesRead: bytes read while executing query.\n",
    "* recordsWritten: number of records written while executing query.\n",
    "* bytesWritten: bytes written while executing query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryExecutionDetail:\n",
    "    query = \"\"\n",
    "    execution_start_time = \"\"\n",
    "    execution_end_time = \"\"\n",
    "    execution_time = \"\"\n",
    "    numStages = \"\"\n",
    "    numTasks= \"\"\n",
    "    executorCpuTime = \"\"\n",
    "    memoryBytesSpilled = \"\"\n",
    "    peakExecutionMemory = \"\"\n",
    "    recordsRead = \"\"\n",
    "    bytesRead = \"\"\n",
    "    recordsWritten = \"\"\n",
    "    bytesWritten = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application details\n",
    "* application_name: name of the applicating in spark.\n",
    "* application_id: application id in spark.\n",
    "* application_start_time: execution start time of application in millisec.\n",
    "* application_end_time: execution end time of application in millisec.\n",
    "* application_execution_time: total time taken in executing the application in millisec.\n",
    "* application_history_url: url t access spark UI for application.\n",
    "* numStages: number of stages used in executing application\n",
    "* numTasks: number of tasks used in executing application\n",
    "* executorCpuTime: total executor CPU time used in executing application in millisec.\n",
    "* memoryBytesSpilled: total memory spilled while executing application in bytes.\n",
    "* peakExecutionMemory: max execution memory used while executing application in bytes.\n",
    "* recordsRead: number of records read while executing application.\n",
    "* bytesRead: bytes read while executing application.\n",
    "* recordsWritten: number of records written while executing application.\n",
    "* bytesWritten: bytes written while executing application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApplicationDetail:\n",
    "    application_name = \"\"\n",
    "    application_id = \"\"\n",
    "    application_start_time = \"\"\n",
    "    application_end_time = \"\"\n",
    "    application_execution_time = \"\"\n",
    "    application_history_url = \"\"\n",
    "    numStages = \"\"\n",
    "    numTasks= \"\"\n",
    "    executorCpuTime = \"\"\n",
    "    memoryBytesSpilled = \"\"\n",
    "    peakExecutionMemory = \"\"\n",
    "    recordsRead = \"\"\n",
    "    bytesRead = \"\"\n",
    "    recordsWritten = \"\"\n",
    "    bytesWritten = \"\"\n",
    "    query_details = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract application details from metrics\n",
    "* **SparkListenerApplicationStart** event contains informations like app name, id, timestamp when application started etc.\n",
    "* **SparkListenerApplicationEnd** event contains timestamp when application ended.\n",
    "* Application details are extractred and stored into application detail object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_detail = ApplicationDetail()\n",
    "\n",
    "app_start_metrics = metrics.filter(\"Event='SparkListenerApplicationStart'\").select(\"App ID\", \"App Name\", \"Timestamp\")\n",
    "app_end_metrics = metrics.filter(\"Event='SparkListenerApplicationEnd'\").select(\"Timestamp\")\n",
    "\n",
    "app_start_metric_dict = app_start_metrics.first().asDict()\n",
    "app_end_metric_dict = app_end_metrics.first().asDict()\n",
    "\n",
    "app_detail.application_name = app_start_metric_dict[\"App Name\"]\n",
    "app_detail.application_id = app_start_metric_dict[\"App ID\"]\n",
    "app_detail.application_start_time = app_start_metric_dict[\"Timestamp\"]\n",
    "app_detail.application_end_time = app_end_metric_dict[\"Timestamp\"]\n",
    "app_detail.application_execution_time = int(app_detail.application_end_time) - int(app_detail.application_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract query details executed in application\n",
    "* **SparkListenerSQLExecutionStart** event contains informations like query execution start time, executin id and query text if local property \"callSite.long\" is set as query.\n",
    "* **SparkListenerSQLExecutionEnd** event contains execution end timestamp for the queries with its execution id.\n",
    "* Joining query execution start info & query execution end info on execution id, we can get all info about queries executed in application.\n",
    "* Query details for each query is saved in seperate object and all query detail object is saved in application detail object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_start_metrics = metrics.filter(\"Event='org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart'\").select(\n",
    "    [col(\"details\").alias(\"query_text\"), col(\"executionId\"), col(\"time\").alias(\"exec_start_time\")])\n",
    "query_end_metrics = metrics.filter(\"Event='org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd'\").select(\n",
    "    [col(\"executionId\"), col(\"time\").alias(\"exec_end_time\")])\n",
    "joined_query_metrics = query_start_metrics.join(query_end_metrics, on=['executionId'], how='inner')\n",
    "\n",
    "joined_query_metrics_lst = joined_query_metrics.sort('executionId').collect()\n",
    "\n",
    "for row in joined_query_metrics_lst:\n",
    "    query_detail = QueryExecutionDetail()\n",
    "    query_detail.query = row[\"query_text\"]\n",
    "    query_detail.execution_start_time = row[\"exec_start_time\"]\n",
    "    query_detail.execution_end_time = row[\"exec_end_time\"]\n",
    "    query_detail.execution_time = int(query_detail.execution_end_time) - int(query_detail.execution_start_time)\n",
    "    app_detail.query_details.append(query_detail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract stages and its metrics used in application \n",
    "* **SparkListenerStageCompleted** event contains all information completed successfully while execution of the application.\n",
    "* Following information are extracted from this event:\n",
    "    * Stage ID: Id to identify stage.\n",
    "    * Submission Time: Timestamp when stage execution started for the stage.\n",
    "    * Completion Time: Timestamp when stage execution completed for the stage.\n",
    "    * Number of Tasks: Total number of tasks created while execution of stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_completed_metrics = metrics.filter(\"Event='SparkListenerStageCompleted'\").select(\"`Stage Info`.*\")\n",
    "stage_completed_metrics.createOrReplaceTempView(\"stage_completed_metrics\")\n",
    "stage_completed_metrics_filtered = spark.sql(\"\"\"\n",
    "          select `Stage ID`,\n",
    "                 min(`Submission Time`) as `Submission Time`, \n",
    "                 max(`Completion Time`) as `Completion Time`, \n",
    "                 sum(`Number of Tasks`) as `Number of Tasks`\n",
    "           from stage_completed_metrics group by `Stage ID` order by `Stage ID`\n",
    "           \"\"\")\n",
    "stage_completed_metrics.createOrReplaceTempView(\"stage_completed_metrics_filtered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract task & its metrics used in application\n",
    "* **SparkListenerTaskEnd** event contains all information about task created and executed successfully while execution of application.\n",
    "* Following informations are extracted from this event:\n",
    "    * Stage ID: Id of the stage under which this task was created.\n",
    "    * Task ID: Task identification number.\n",
    "    * Executor CPU Time: total executor CPU time used in executing the task in millisec.\n",
    "    * Memory Bytes Spilled: total memory spilled while executing the task in bytes.\n",
    "    * Peak Memory Execution: max execution memory used while executing the task in bytes.\n",
    "    * Records Read: number of records read while executing the task.\n",
    "    * Bytes Read: bytes read while executing the task.\n",
    "    * Records Written: number of records written while the task application.\n",
    "    * Bytes Written: bytes written while executing the task.\n",
    "* Stage metrics & task metrics are joined based on stage id and metrics for each stage is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_end_metrics = metrics.filter(\"Event='SparkListenerTaskEnd'\").select(\"Stage ID\", \"Task Info.*\", \"Task Metrics.*\")\n",
    "task_end_metrics.createOrReplaceTempView(\"task_end_metrics\")\n",
    "\n",
    "task_end_metrics_filtered = task_end_metrics.select(\"Task ID\", \"Stage ID\", \"Executor CPU Time\", \"Memory Bytes Spilled\",\n",
    "                                                    \"Output Metrics.*\",\"Input Metrics.*\", \"Finish Time\")\n",
    "task_end_metrics_filtered.createOrReplaceTempView(\"task_end_metrics_filtered\")\n",
    "\n",
    "task_end_metrics_acccumulables = spark.sql(\"\"\"\n",
    "    select t1.`Task ID`, t2.Name, cast(t2.Value as bigint) as `Peak Execution Memory` from task_end_metrics as t1 \n",
    "    lateral view explode(t1.Accumulables) as t2 \n",
    "    where t2.Name = 'internal.metrics.peakExecutionMemory'\n",
    "    \"\"\")\n",
    "task_end_metrics_acccumulables.createOrReplaceTempView(\"task_end_metrics_accumulables\")\n",
    "task_metrics_aggregated = spark.sql(\"\"\"\n",
    "          select t1.`Stage ID`,  \n",
    "                  count(t1.`Task ID`) as `No. of Tasks`, \n",
    "                  sum(t1.`Executor CPU Time`) as `Total Executor CPU Time`,\n",
    "                  sum(t1.`Memory Bytes Spilled`) as `Total Memory Bytes Spilled`,\n",
    "                  max(t2.`Peak Execution Memory`) as `Peak Execution Memory`,\n",
    "                  sum(t1.`Bytes Written`) as `Total Bytes Written`,\n",
    "                  sum(t1.`Records Written`) as `Total Records Written`,\n",
    "                  sum(t1.`Bytes Read`) as `Total Bytes Read`,\n",
    "                  sum(t1.`Records Read`) as `Total Records Read`\n",
    "           from task_end_metrics_filtered t1 left join task_end_metrics_accumulables t2\n",
    "           on (t1.`Task ID` = t2.`Task ID`) \n",
    "           group by `Stage ID` order by `Stage ID`\n",
    "          \"\"\")\n",
    "task_metrics_aggregated.createOrReplaceTempView(\"task_metrics_aggregated\")\n",
    "joined_metrics = spark.sql(\"\"\"\n",
    "      select sm.`Stage ID` as `Stage ID`,\n",
    "             sm.`Submission Time` as `Submission Time`,\n",
    "             sm.`Completion Time` as `Completion Time`,\n",
    "             sm.`Number of Tasks` as `Number of Tasks`,\n",
    "             tm.`Total Executor CPU Time` as `Total Executor CPU Time`,\n",
    "             tm.`Total Memory Bytes Spilled` as `Total Memory Bytes Spilled`,\n",
    "             tm.`Peak Execution Memory` as `Peak Execution Memory`,\n",
    "             tm.`Total Bytes Written` as `Total Bytes Written`,\n",
    "             tm.`Total Records Written` as `Total Records Written`,\n",
    "             tm.`Total Bytes Read` as `Total Bytes Read`,\n",
    "             tm.`Total Records Read` as `Total Records Read`\n",
    "       from stage_completed_metrics_filtered as sm inner join task_metrics_aggregated as tm \n",
    "       on (sm.`Stage ID` = tm.`Stage ID`) order by `Stage ID`\n",
    "      \"\"\")\n",
    "joined_metrics.createOrReplaceTempView(\"joined_metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Query metrices\n",
    "* Based on submission time of stages & completion time of stage and start time & end time of query. We can calculate metrics for each query.\n",
    "* Submission time of the stage is mapped to execution start time of the query.\n",
    "* Completion time of the stage is mapped to execution end time of the query.\n",
    "* All stages and tasks created and executed b/w start time & end time of the query are for that particular query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_metrics(execution_start_time, execution_end_time):\n",
    "    query_metrics = spark.sql(\"\"\"\n",
    "      select count(*) as `Number of Stages`,\n",
    "             max(`Completion Time`) - min(`Submission Time`) as `Execution Time`,\n",
    "             sum(`Number of Tasks`) as `Number of Tasks`,\n",
    "             sum(`Total Executor CPU Time`) as `Total Executor CPU Time`,\n",
    "             sum(`Total Memory Bytes Spilled`) as `Total Memory Bytes Spilled`,\n",
    "             max(`Peak Execution Memory`) as `Peak Execution Memory`,\n",
    "             sum(`Total Bytes Written`) as `Total Bytes Written`,\n",
    "             sum(`Total Records Written`) as `Total Records Written`,\n",
    "             sum(`Total Bytes Read`) as `Total Bytes Read`,\n",
    "             sum(`Total Records Read`) as `Total Records Read`\n",
    "       from joined_metrics where `Submission Time` >= \"\"\" + str(execution_start_time) + \n",
    "                              \"\"\" and `Completion Time` <= \"\"\" + str(execution_end_time))\n",
    "    return query_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValue(dict, key, isString):\n",
    "    if key in dict.keys() and dict[key] != 'None' and dict[key]is not None:\n",
    "        if isString:\n",
    "            return str(dict[key])\n",
    "        return int(dict[key])\n",
    "    else: \n",
    "        if isString:\n",
    "            return \"\"\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Application metrics\n",
    "* After metrics for each query is calculated, we aggregate them to calculate metrics for the action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_application_metrics(app_detail):\n",
    "    total_num_stages = 0\n",
    "    total_num_tasks = 0\n",
    "    total_executor_cpu_time = 0\n",
    "    total_memory_bytes_spilled = 0\n",
    "    peak_execution_memory = 0\n",
    "    total_records_read = 0\n",
    "    total_bytes_read = 0\n",
    "    total_records_written = 0\n",
    "    total_bytes_written = 0\n",
    "    for query in app_detail.query_details:\n",
    "        total_num_stages = total_num_stages + query.numStages\n",
    "        total_num_tasks = total_num_tasks + query.numTasks\n",
    "        total_executor_cpu_time = total_executor_cpu_time + query.executorCpuTime\n",
    "        total_memory_bytes_spilled = total_memory_bytes_spilled + query.memoryBytesSpilled\n",
    "        if peak_execution_memory < query.peakExecutionMemory:\n",
    "            peak_execution_memory = query.peakExecutionMemory\n",
    "        total_records_read = total_records_read + query.recordsRead\n",
    "        total_bytes_read = total_bytes_read + query.bytesRead\n",
    "        total_records_written = total_records_written + query.recordsWritten\n",
    "        total_bytes_written = total_bytes_written + query.bytesWritten\n",
    "        \n",
    "    app_detail.numStages = total_num_stages\n",
    "    app_detail.numTasks= total_num_tasks\n",
    "    app_detail.executorCpuTime = total_executor_cpu_time\n",
    "    app_detail.memoryBytesSpilled = total_memory_bytes_spilled\n",
    "    app_detail.peakExecutionMemory = peak_execution_memory\n",
    "    app_detail.recordsRead = total_records_read\n",
    "    app_detail.bytesRead = total_bytes_read\n",
    "    app_detail.recordsWritten = total_records_written\n",
    "    app_detail.bytesWritten = total_bytes_written\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating metrics for each query\n",
    "* For every query we seperate their metrics based on its execution start time and execution end time based.\n",
    "* Extracted metrics are then populated into respective query object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_peak_memories = []\n",
    "for query in app_detail.query_details:\n",
    "    execution_start_time = query.execution_start_time\n",
    "    execution_end_time = query.execution_end_time\n",
    "    query_metrics = get_query_metrics(execution_start_time, execution_end_time)\n",
    "    num_of_agg_rows = query_metrics.count()\n",
    "    query_metrics_dict = {}\n",
    "    if num_of_agg_rows > 0:\n",
    "        query_metrics_dict = query_metrics.first().asDict()\n",
    "    query.numStages = getValue(query_metrics_dict, \"Number of Stages\", False)\n",
    "    query.numTasks= getValue(query_metrics_dict, \"Number of Tasks\", False)\n",
    "    executor_cpu_time = getValue(query_metrics_dict, \"Total Executor CPU Time\", False)\n",
    "    query.executorCpuTime = executor_cpu_time // 1000000\n",
    "    query.memoryBytesSpilled = getValue(query_metrics_dict, \"Total Memory Bytes Spilled\", False)\n",
    "    peak_execution_memory = getValue(query_metrics_dict, \"Peak Execution Memory\", False)\n",
    "    query.peakExecutionMemory = peak_execution_memory\n",
    "    query_peak_memories.append(peak_execution_memory)\n",
    "    query.recordsRead = getValue(query_metrics_dict, \"Total Records Read\", False)\n",
    "    query.bytesRead = getValue(query_metrics_dict, \"Total Bytes Read\", False)\n",
    "    query.recordsWritten = getValue(query_metrics_dict, \"Total Records Written\", False)\n",
    "    query.bytesWritten = getValue(query_metrics_dict, \"Total Bytes Written\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_application_metrics(app_detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_row(content, row):\n",
    "    return content + \"\\n\" + row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report in CSV\n",
    "* After metrics for application is calculated, we prepare a CSV report for the application and queries executed in it.\n",
    "* The report file is wrriten with the name in the format application name followed by application id and saved to given output path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"{}/{}_{}.csv\".format(output_dir, app_detail.application_name, app_detail.application_id)\n",
    "content = '\"Action Detail\"'\n",
    "content = append_row(content, '\"Application Name:\",\"{}\"'.format(app_detail.application_name))\n",
    "content = append_row(content, '\"No. of Queries:\",\"{}\"'.format(len(app_detail.query_details)))\n",
    "content = append_row(content, '\"Start Time:\",\"{}\"'.format(app_detail.application_start_time))\n",
    "content = append_row(content, '\"End Time:\",\"{}\"'.format(app_detail.application_end_time))\n",
    "content = append_row(content, '\"Execution Time:\",\"{}\"'.format(app_detail.application_execution_time))\n",
    "content = append_row(content, '\"Total No. of Stages:\",\"{}\"'.format(app_detail.numStages))\n",
    "content = append_row(content, '\"Total No. of Tasks:\",\"{}\"'.format(app_detail.numTasks))\n",
    "content = append_row(content, '\"Executor CPU Time:\",\"{}\"'.format(app_detail.executorCpuTime))\n",
    "content = append_row(content, '\"Total Memory Bytes Spilled:\",\"{}\"'.format(app_detail.memoryBytesSpilled))\n",
    "content = append_row(content, '\"Peak Execution Memory:\",\"{}\"'.format(app_detail.peakExecutionMemory))\n",
    "content = append_row(content, '\"Total Records Read:\",\"{}\"'.format(app_detail.recordsRead))\n",
    "content = append_row(content, '\"Total Bytes Read:\",\"{}\"'.format(app_detail.bytesRead))\n",
    "content = append_row(content, '\"Total Records Written:\",\"{}\"'.format(app_detail.recordsWritten))\n",
    "content = append_row(content, '\"Total Bytes Written:\",\"{}\"'.format(app_detail.bytesWritten))\n",
    "content = append_row(content, '\"Spark Job History URL:\",\"{}\"'.format(app_detail.application_history_url))\n",
    "content = append_row(content, '\\n\"Query Wise Detail\"')\n",
    "header = '\"S. No.\",\"Query\",\"Query Execution Start Time\",\"Query Execution End Time\",\\\n",
    "\"Total Execution Time\",\"No. of Stages\",\"No. of Tasks\",\\\n",
    "\"Executor CPU Time\",\"Memory Bytes Spilled\",\"Peak Execution Memory\",\"Records Read\",\\\n",
    "\"Bytes Read\",\"Records Written\",\"Bytes Written\"'\n",
    "content = append_row(content, header)\n",
    "for query_index, query_detail in enumerate(app_detail.query_details):\n",
    "    executor_cpu_time = query_detail.executorCpuTime\n",
    "    mem_bytes_spilled = str(query_detail.memoryBytesSpilled)\n",
    "    peak_exec_mem = str(query_detail.peakExecutionMemory)\n",
    "    bytes_read = str(query_detail.bytesRead)\n",
    "    bytes_written = str(query_detail.bytesWritten)\n",
    "    query_text = query_detail.query.replace('\"', \"'\").strip()\n",
    "    content = append_row(content, '\"{}\",\"{}\",\"{}\",\"{}\",\"{}\",\"{}\",\"{}\",\"{}\",\"{}\",\"{}\",\"{}\",\"{}\",\"{}\",\"{}\"'.format(\n",
    "        query_index + 1, query_text, query_detail.execution_start_time, query_detail.execution_end_time, \n",
    "        query_detail.execution_time, query_detail.numStages, query_detail.numTasks, \n",
    "        executor_cpu_time, mem_bytes_spilled, peak_exec_mem, query_detail.recordsRead, bytes_read, \n",
    "        query_detail.recordsWritten, bytes_written))\n",
    "content = append_row(content, \"\\n\")\n",
    "\n",
    "workflow_summary_file = open(filename, 'w')\n",
    "workflow_summary_file.write(content)\n",
    "workflow_summary_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "from openpyxl.chart import ScatterChart, Reference , Series\n",
    "\n",
    "filename = output_dir + \"/chart.xlsx\"\n",
    "workbook = Workbook()\n",
    "worksheet = workbook.active\n",
    "\n",
    "worksheet.cell(column=1, row=1, value=\"Action ID\")\n",
    "worksheet.cell(column=2, row=1, value=\"Query ID\")\n",
    "worksheet.cell(column=3, row=1, value=\"Peak Execution Memory\")\n",
    "row=2\n",
    "for i, item in enumerate(query_peak_memories): \n",
    "    worksheet.cell(column=1, row=row, value=1)\n",
    "    worksheet.cell(column=2, row=row, value=i)\n",
    "    worksheet.cell(column=3, row=row, value=int(item))\n",
    "    row += 1\n",
    "\n",
    "chart = ScatterChart()\n",
    "chart.title = \"Peak Memory Graph\"\n",
    "chart.style = 13\n",
    "chart.y_axis.title = 'Peak Execution Memory'\n",
    "chart.x_axis.title = 'Query ID'\n",
    "x_data = Reference(worksheet, min_col=2, min_row=2, max_row=len(worksheet['B']))\n",
    "y_data = Reference(worksheet, min_col=3, min_row=1, max_row=len(worksheet['C']))\n",
    "series = Series(y_data, x_data, title_from_data=True)\n",
    "chart.series.append(series)\n",
    "chart.height = 11\n",
    "chart.width = 28\n",
    "worksheet.add_chart(chart, 'E3')  \n",
    "workbook.save(filename=filename)\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
